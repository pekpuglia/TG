
All code was implemented in the Julia language due to the availability of \textit{packages} for subproblems of this work. In the next section, several components of the solution to the problem of optimization of impulsive maneuvers are detailed, and the following section assembles all components into the full optimization algorithm.

TODO replace two body with Keplerian

TODO delta x f

\section{Components}

The optimization of impulsive maneuvers relies on the representation and manipulation of several concepts in a programmatic fashion. In particular there is a need for a nonlinear numerical solver, a numerical way of propagating orbits, a representation for sequences of impulses and coasting arcs, an implicit formulation for maneuvers amenable to optimization, and a way of calculating primer vector trajectories on multi-impulse maneuvers. Each of those components will be explored in the following sections.

\subsection{Nonlinear solver}\label{sssec:solver}

Nonlinear solvers are algorithms which iteratively approximate the solution to a system of nonlinear equations or a constrained optimization problem. Their choice is problem dependent and problems must be stated in a format compatible with the desired solver. Many algorithms exist, with different smoothness requirements, convergence properties, or optimality guarantees. 

Of interest to this work are local gradient-based algorithms. They are well suited to nonlinear (but twice differentiable) problems with continuous variables subject to nonlinear constraints. By exploiting the gradient, and sometimes the Hessian of the cost as well, faster algorithms are available. The downside of this type of algorithm is that they return a \textit{local} solution, that is, a solution where no small change can improve it. Those are, in general, not \textit{global} solutions. Orbital maneuver problems have many local solutions of varying qualities, meaning that this distinction must be accounted for. The algorithm takes an initial guess as a parameter and improves it, simultaneously satisfying constraints and minimizing the objective function.

Julia offers a multitude of nonlinear solvers, each with different scope, interface, and algorithms. This work has chosen to use \texttt{CasADi}~\cite{casadi}, a package which offers a modelling language for optimization problems that is quite close to mathematical notation, and is the industry standard for optimal control. Internally, CasADi converts the problem to a format accepted by Ipopt~\cite{ipopt}, the default nonlinear solver in CasaDi. Ipopt is an open-source nonlinear solver widely recognized for its speed and precision, outperforming many competitors and being quite flexible. It is especially well suited to problems with many variables (up to thousands) with sparse constraints (that is, constraints that depend only on small subsets of variables). It is a Newton-like algorithm with many optimizations to iteration acceptance criteria, filtering of bad iterates, and many configurable parameters. Internally, this means that Ipopt must solve very large linear systems (Jacobian inversion) as a part of the solve process, which introduces normalization concerns (discussed later).

This solver allows for the specification of lower and upper bounds of variables separately to the specification of inequality constraints. Variable bounds are guaranteed to be respected at all iterations; inequality constraints are only guaranteed to be satisfied at the converged solution, if the problem is feasible. This distinction is important because some constraints define the domain of problem and should never be violated, such as positivity of time durations; other constraints are problem-based and therefore can be violated during the iteration process.

Ipopt uses a barrier function method to handle constraints. This means that the initial guess is not \textit{required} to satisfy all constraints and, in all iterations except the final, converged iterate, constraint violation is allowed. The user-input cost function is replaced by a mixed objective containing the cost function a cost on constraint violation. During iteration, constraint violation is increasingly penalized until a solution in the feasible set is found, where optimization can continue. A corollary of this scheme is that even if the initial guess is very close to satisfying some constraints, but not others, intermediate iterates may worsen constraint violation and objective function in favor of this mixed objective.

Ipopt also comes with a host of configuration options. Parameters worth mentioning are the tolerance for constraint violation \(\varepsilon\), maximum iteration count, maximum solve time, and maximum \textit{restoration iterations}. Restoration iterations are iterations in which no attempt to improve the objective function is made, and the solver focuses only on satisfying constraints. This usually happens when constraints are "hard", the feasible region of the problem is small, or iterates diverge. Limiting this reduces time wasted on trying to optimize a bad initial guess.

\subsection{Orbit Propagation}\label{sec:orbit_propagation}

The implementation of an orbit propagator concerns itself with the implementation of the function \(p_o(\mathbf{x}, t)\) introduced in Equation~\eqref{eq:orbit_propagator}. The orbit propagation function depends on the model chosen. Three models are established in this work, the two body model, the J2 model and the J2+Drag model, which are introduced at the end of this section. Two different cases are to be considered: ``explicit'' propagation, where numerical inputs are available and a numerical output is desired; and ``implicit'' propagation, where the propagation step is a part of a larger solver.

Brazil's National Institute of Space Research (INPE) developed a package for orbit propagation and analysis with several models (Kepler, J2 semi-analytical secular and short term, among others) called \texttt{SatelliteToolbox}~\cite{satellitetoolbox}. It provides quite convient functions for converting between the Cartesian state vector \(\begin{bmatrix}
    \mathbf{r}^T & \mathbf{v}^T
\end{bmatrix}^T\) and the Keplerian elements, as well as functions for the propagation of orbits by some specified amount of time \(t_p\). Its algorithms were chosen with precision around edge cases in mind~\cite{rv_to_kepler}, making it numerically precise but unsuitable for nonlinear solvers, which expect differentiable functions everywhere. The functions in this package are also limited to elliptic orbits, which are not guaranteed to be found during iteration inside a numerical solver like Ipopt.

Therefore, this is an auxiliary package used for verification, initial guess generation, and direct numerical propagation whenever required. When propagation is required in the statement of a nonlinear optimization problem, another method for orbit propagation is required. Despite being useful for explicit propagation, Keplerian elements are unsuited for optimization (at least with the chosen solver, see Section~\ref{sssec:solver}). This can be seen from the equation relating the true anomaly \(\theta\) and the eccentric anomaly \(E\), Equation~\eqref{eq:true_exc_anom}, discussed in Table~\ref{tab:kep_ecc_true}. In summary, the anomaly equations require special treatment close to the apogee to avoid infinities or discontinuities.

\begin{table}[htbp]
    \centering
    \begin{tabular}{cccc} \toprule
        Form & LHS value at apogee & RHS value at apogee & Comment  \\ \midrule
        \(\tan{\frac{\theta}{2}} = \sqrt{\frac{1+e}{1-e}} \tan{\frac{E}{2}}\) & \(+\infty\) & \(+\infty\) & \parbox{2.5cm}{Value unsuitable for computation} \\
        \(\theta = 2\arctan{\sqrt{\frac{1+e}{1-e}} \tan{\frac{E}{2}}}\) & \(\pi\) & \(\pm\pi\) & \parbox{2.5cm}{Not continuous \(\therefore\) not differentiable} \\ \bottomrule
    \end{tabular}
    \caption{Problems with the Keplerian elements formulation exemplified with the relationship between eccentric and true anomalies}
    \label{tab:kep_ecc_true}
\end{table}

Therefore, the dynamics in Cartesian coordinates were chosen for implicit propagation, due to the differentiability of this model in the usual range of orbital variables. Many methods for integrating dynamical systems for optimal control exist, such as collocation, pseudospectral methods, direct shooting, and multiple shooting~\cite{numerical_recipes}. Multiple shooting was chosen since it leads to a numerically stable problem and is standard in optimal control. An eighth-order Runge-Kutta (RK8) method~\cite{rk8} was used for discretizing the dynamical equations. Let  \(\mathbf{x}_{\text{next}} = f_{RK}(\mathbf{x}_{\text{prev}}, \Delta t)\) be the RK8 integration function from Cartesian state \(\x_{\text{prev}}\) to Cartesian state \(\mathbf{x}_{\text{next}}\) over a time step \(\Delta t\). This discretization scheme is agnostic to the dynamics of the system, that is, one can "drop-in" the two body model, the J2 model, or the J2-Drag model and the scheme remains the same, which is quite convenient.

The multiple shooting implicit orbit propagation uses \(N\) discretization points for a coasting arc of duration \(d_c\), which are parameterized with Cartesian state vector variables \(\x^j \in \R^6, j=1,\dots,N\) subject to 
\begin{equation}
    \mathbf{x}^{j+1} = f_{RK}(\frac{d_c}{N - 1}, \mathbf{x}^j), j = 1, \dots, N.
\end{equation}

To complete the implicit description, \(\dim \mathbf{x} = 6\) boundary conditions are needed. These may be an initial condition, a final condition, or an impulsive boundary condition between two arcs.

%this part is messy
% Let \(\mathbf{x}_{\text{next}} = f_{RK}(\mathbf{x}_{\text{prev}}, \Delta t)\) be the dynamics function discretized through the eighth order Runge Kutta method. Then a number \(N\) of discretization points is chosen and \(N\) state vector variables \(\mathbf{x}^j, j=1,\dots,N\) are created belonging to an array \(\chi \in \mathbb{R}^{6 \times (N)}\). They are subject to the constraints
% \begin{equation}
%     \mathbf{x}^{j+1} = f_{RK}(\mathbf{x}^j, \frac{t_p}{N}), j = 1, \dots, N.
% \end{equation}
% This leaves \(\dim \mathbf{x} = 6\) degrees of freedom, which are to be specified with a boundary condition. This boundary condition can be an initial condition, a final condition or relation to another coasting segment through an impulse, as will be discussed in Section~\ref{sec:impulsive_statement}. Thus, this parameterization of orbital propagation is \textit{isoconstrained}.

\subsubsection{Orbital Models}

Three orbital models are proposed for this work. The first is two body dynamics, with dynamical system given in Equation~\eqref{eq:kepler_dyn}. The other two are perturbed orbital models chosen as representatives of the class of general conservative models, and general non-conservative models, respecting the relative magnitudes of orbital perturbations. The J2 Model, with dynamics given in Equation~\eqref{eq:j2_dyn}, was chosen as the representative of general conservative models. For the non-conservative model, the acceleration due to drag from Equation~\eqref{eq:acc_drag} is added to the dynamical equation of the J2 Model, yielding the dynamics of the J2+Drag Model:
\begin{equation}
    \ddot{\pos} = -\frac{\mu}{r^3} \pos + \acc_{J2} + \acc_{D}.
\end{equation}

Table summarizes the models, model classes and dynamics used.

\begin{table}[htbp]
    \centering
    \begin{tabular}{ccc}\toprule
        Model & Model Class & Dynamics \\ \midrule
        Keplerian & Two Body & \(\ddot{\pos} = -\frac{\mu}{r^3} \pos\) \\
        J2 & Conservative & \(\ddot{\pos} = -\frac{\mu}{r^3} \pos + \acc_{J2}\) \\
        J2+Drag & Non-conservative & \(\ddot{\pos} = -\frac{\mu}{r^3} \pos + \acc_{J2} + \acc_{D}\) \\ \bottomrule
    \end{tabular}
    \caption{Summary of orbital models, classes and dynamics considered.}
    \label{tab:orb_models}
\end{table}

\subsection{Maneuver Propagation}\label{sec:maneuver_propagation}

Impulsive maneuvers are characterized by a sequence of impulses and coasting arcs. A notation for maneuvers is introduced, where \texttt{C} represents a coasting arc, and \texttt{I} represents an impulse. Any alternating sequence \(\mathcal{S} \in \{\texttt{C}, \texttt{I}\}^{n_c + n_i}\), where \(n_c\) is the number of coasting arcs and \(n_i\) is the number of impulses, with 2 or more impulses makes a valid maneuver: \texttt{ICI}, \texttt{ICIC}, \texttt{CICICICIC}, etc. Maneuvers need at least 2 impulses to be able to take any initial state to any final state (see Section~\ref{sec:imp_prop_model}). Also, let \(\mathcal{I} = \{i \in 1,\dots,n_i+n_c | \mathcal{S}_i = \texttt{I}\}\) and \(\mathcal{C} = \{c \in 1,\dots,n_i+n_c | \mathcal{S}_c = \texttt{C}\}\) be the sets of impulse and coast indices respectively. Figure~\ref{fig:maneuver_propagation} illustrates the algorithm for propagating a maneuver: at impulses, a velocity discontinuity is applied; at coasting arcs, the orbit is propagated. This algorithm follows the specified sequence of maneuvers for given values of impulse magnitudes and directions, and coast durations. 

Implicit maneuver propagation is required for optimization. For this, coasts are parameterized according to the multiple shooting scheme of last section, and impulsive boundary conditions between arcs are added as constraints.  


\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}
        \node (init) [startstop] {Initial state};
        \node (dots1) [process, right = of init] {\ldots};
        \node (imp) [process, below = of dots1] {\textbf{Impulse}
        
        Velocity discontinuity};
        \node (coast) [process, right = of imp] {\textbf{Coast}
        
        Orbit 
        
        propagation};
        \node (dots2) [process, below = of coast] {\ldots};
        \node (final) [startstop, right = of dots2] {Final state};

        \draw [arrow] (init) -- (dots1);
        \draw [arrow] (dots1) -- (imp);
        \draw [arrow] (imp) -- (coast);
        \draw [arrow] (coast) -- (dots2);
        \draw [arrow] (dots2) -- (final);

    \end{tikzpicture}
    \caption{Maneuver propagation scheme.}
    \label{fig:maneuver_propagation}
\end{figure}

%talk about random start, stopping early
%talk about primer vector algorithm
%talk about repropagation

\subsection{Maneuver multiple shooting problem statement}

The full maneuver optimization problem, in its multiple shooting formulation, shall be stated in this section. The input parameters are:
\begin{enumerate}
    \item \(\mathbf{r}_1\), \(\mathbf{v}_1\): initial orbital position and velocity;
    \item \(\mathbf{r}_2\), \(\mathbf{v}_2\): final orbital position and velocity;
    \item \(t_f\): transfer time;
    \item \(N\): number of integration steps per coasting arc.
    \item \(\mathcal{S} \in \{\texttt{C}, \texttt{I}\}^{n_c + n_i}\): the desired sequence of coasts and impulses.
\end{enumerate}

The problem's definition and variable set dynamically depends on the input sequence. The \(i\)-th impulse is described by the variables\footnote{The problem could have been parameterized with vector quantities for the changes in velocities, \(\Delta \vec{\mathbf{v}}\), but the objective function would then be stated \(\sum \sqrt{\Delta \vec{\mathbf{v}}^T \Delta \vec{\mathbf{v}}}\), which is not differentiable at \(\Delta \vec {\mathbf{v}} = 0\), which is inconvenient.}
\begin{enumerate}
    \item \(\Delta v_i \geq 0\): magnitude of the impulse;
    \item \(\hat{\uc}_i \in \R^3\): direction of the impulse.
\end{enumerate}

The \(c\)-th coasting arc is described by:
\begin{enumerate}
    \item \(d_c \geq 0\): total duration of the arc;
    \item \(\x^j_c \in \R^6, j=1,\dots,N\): tate vector variables for each coasting arc. 
\end{enumerate}

Some care needs to be taken about the first sequence element, an impulse or coast, since this changes the necessary constraints for the initial and final conditions. The full multiple shooting problem for the optimization of the impulsive maneuver is:

\begin{align}\label{eq:ms_problem}
    \begin{tabular}{cl}
     \(\min\)                              & \(\sum_{i \in \mathcal{I}} \Delta v_i\)\\
    \(\Delta v_i  \in \R_+, i \in \mathcal{I}\), &  \\
    \(\hat{\uc}_i \in \R^3, i \in \mathcal{I}\),     & \\
    \(d_c         \in \R_+, c \in \mathcal{C}\),     & \\
    \(\x^j_c      \in \R^6, j=1,\dots,N, c \in \mathcal{C}\) & \\
    \textbf{subject to:}        & \\
    Total time                  & \(\sum_{c \in \mathcal{C}} d_c = t_f\) \\
    Unit directions             & \(\hat{\uc}_i^T \hat{\uc}_i = 1, i \in \mathcal{I}\) \\
    Propagation of coasts       & \(\x^{j+1}_c = f_{RK}(\frac{d_c}{N-1}, \x^j_c)\), \\
                                & \(j=1,\dots,N-1, c \in \mathcal{C}\) \\
    Impulse boundary conditions & \(\x^1_{i+1} = \x^{N}_{i-1} + \begin{bmatrix}
        0_{3\times1} \\ \Delta v_i \hat{\mathbf{u}}_i
    \end{bmatrix}\), \\
                                & \(i \in \mathcal{I}, i \neq 1, n_i+n_c\) \\
    Initial condition           & \(\x_1^1 = \begin{bmatrix}
        \mathbf{r}_1 \\ \mathbf{v}_1
    \end{bmatrix}, 1 \in \mathcal{C}\) \\
                                & \(\x_2^1 = \begin{bmatrix}
                                    \mathbf{r}_1 \\ \mathbf{v}_1 + \Delta v_1 \hat{\mathbf{u}}_1
                                \end{bmatrix}, 1 \in \mathcal{I}\) \\
    Final condition             & \(x_c^N = \begin{bmatrix}
        \mathbf{r}_2 \\ \mathbf{v}_2
    \end{bmatrix}, c = n_i+n_c \in \mathcal{C}\) \\
                                & \(x_{i-1}^N + \begin{bmatrix}
                                    0_{3\times1} \\ \Delta v_i \hat{\mathbf{u}}_i
                                \end{bmatrix} = \begin{bmatrix}
                                    \mathbf{r}_2 \\ \mathbf{v}_2
                                \end{bmatrix}, i = n_i+n_c \in \mathcal{I}\)
    \end{tabular}
 \end{align}

% The solver should be initialized with a feasible, but not necessarily optimal solution, for better convergence (since Ipopt is a local solver, the choice of initial guesses is important). Values for \(\Delta t_1\) and \(\Delta t_2\) should be proposed based on physical reasoning. Then, the variables of the first and last coasting arcs are initialized with direct orbital propagation results (computed with the \texttt{SatelliteToolbox} package). The second coasting arc, between the impulses, is initialized with the solution to the Lambert problem between the final position of the first coasting arc and the initial position of the last coasting arc. Finally, the variables concerning the impulses' magnitudes and directions are initialized with the difference in velocity between consecutive arcs.

As discussed in Section~\ref{sssec:solver}, the solver should be initialized with an initial guess that is not far from being feasible. For multiple shooting schemes, this means satisfying the dynamical constraints, but possibly not the final condition constraint. Therefore, initial guesses can be generated by guessing impulse magnitudes and directions, coast durations and applying the maneuver propagation algorithm from Section~\ref{sec:maneuver_propagation}. Early experimentation shows that coast durations have the biggest impact on the optimization result, so impulse magnitudes can be set to 0. Therefore, to best explore the available solutions and somewhat counteract the local nature of Ipopt, a random sampling scheme was setup, which samples coast durations adding up to the total time (TODO appendix random gen?) and creates a "zero" maneuver composed of coasting arcs along the initial orbit and zero magnitude impulses at specified times. This, combined with early stopping in divergent cases (limiting restoration iterations mentioned in~\ref{sssec:solver}), allowed for speedy optimization of short and mid duration maneuvers.

Finally, some practical considerations about the multiple shooting scheme are presented. During optimization, dynamical constraints are allowed to be violated up to the solver's tolerance \(\varepsilon\), which warrants a verification with forward propagation of the maneuver. The difference between the final position of the forward-propagated maneuver and the desired final position \(\pos_2\) shall be denoted \(\Delta \pos_f\) in the analysis of numerical results. The issues of normalizing variables and having a twice differentiable model are discussed in the next sections.

\subsubsection{Variable normalization}

Cartesian orbital variables regularly take on values on the order of \(10^6\). At this range of values, floating-point number are more spaced out than on the order of \(1\), meaning that the optimal values for a problem may lie between two consecutive floating point number representations. In addition, Jacobians evaluated at big variable values tend to be ill-conditioned, leading to worse iterates due to lost precision. All of this leads to the need of normalizing variables.

Variable normalization was done by rescaling physical units for length and time before assembling the multiple shooting problem. Let \(L\) be a normalizing length, and \(T\) be a normalizing time. Then, a change of units is performed and new, rescaled physical parameters are found. Let \(\tilde{\bullet}\) represent the rescaled version of any variable \(\bullet\). This procedure is exemplified with the two-body model, but is analogous for the other models explored in the work:
\begin{equation}
    \ddot{\pos} = -\frac{\mu}{r^3} \pos \iff \frac{L}{T^2}\frac{d^2 \tilde{\pos}}{d \tilde{t}} = -\frac{\mu}{L^2 \tilde{r}^3} \tilde{\pos} \iff \frac{d^2 \tilde{\pos}}{d \tilde{t}} = -\frac{\tilde{\mu}}{\tilde{r}^3} \tilde{\pos}
\end{equation}
with \(\tilde{\mu} = \mu \frac{T^2}{L^3}\). Length scaling was usually taken to be the average of semimajor axes of the initial and final orbits, and time scaling was set either to \(1\) (no scaling) or one orbital period of an orbit with semimajor axis equal to the length scaling factor.

\subsubsection{Drag smoothing}

The US Standard Atmosphere model introduced in Section~\ref{sssec:drag} is defined piecewise, wich is not compatible with Ipopt. A smooth reformulation is therefore needed. This will be achieved in two steps.

Firstly, define the unit interval indicator function \(\mathbb{I} (x)\) as
\begin{equation}
    \mathbb{I} (x) = \begin{cases}
        1, 0 \leq x < 1 \\
        0, \text{ otherwise}
    \end{cases}
\end{equation}
and rewrite the piecewise definition for \(\rho(r)\) in Equation~\eqref{eq:rho} as
\begin{equation}
    \rho(r) = \sum_{i = 1}^{28} \rho_i \exp{\big(-\frac{\left(r - (h_i + R)\right)}{H_i}\big)} \mathbb{I}(\frac{r - R - h_i}{h_{i+1} - h_i}).
\end{equation}

Secondly, define a smooth indicator function \(\sigma_k(x)\) as
\begin{equation}
    \sigma_k(x) = \frac{1}{2} \left(\tanh{k x} + \tanh{k (1 - x)}\right)
\end{equation}
for some (large) value of \(k > 0\). Then, the smooth density model \(\rho_s(r)\) can be written
\begin{equation}
    \rho(r) = \sum_{i = 1}^{28} \rho_i \exp{\big(-\frac{\left(r - (h_i + R)\right)}{H_i}\big)} \sigma_k(\frac{r - R - h_i}{h_{i+1} - h_i}),
\end{equation}
thus giving an approximate, twice differentiable model as desired. With \(k = 200\), 
\begin{equation}
    \max_r \frac{\lvert \rho(r) - \rho_s(r) \rvert}{\rho(r)} \leq 2\%,
\end{equation}
which was deemed an acceptable approximation error.

\subsection{Primer vector algorithm}

The primer vector calculation methods from Sections~\ref{sssec:pv_calc_cons} and~\ref{sssec:pv_calc_ncon} apply only between two consecutive impulses. Figure~\ref{fig:pv_calc} shows a diagram with the algorithm for a general maneuver. First, the primer vector trajectory between all pairs of consecutive impulses is calculated by means of Equations~\eqref{eq:pv_deltav}-\eqref{eq:pdot1_singular} and the PVTM\@. If the STM method is valid for the orbital model being used, it can be directly estimated by the Jacobian of the final condition w.r.t.\ to the initial condition, as in Equation~\eqref{eq:stm_def}, which is computed handily with Julia's ForwardDiff package~\cite{forward_diff}. Then, if the maneuver starts with a coasting arc, the primer vector is propagated backwards with its transition matrix. Similarly, for the last impulse, the primer vector is propagated forwards. 

Thereafter, the primer vector trajectory is analyzed. By construction, \(\mathbf{p}\) should be continuous, and \(\mathbf{p} = \hat{\uc}\). What is left to verify is whether \(\dot{\mathbf{p}}\) is continuous and \(\lVert \mathbf{p} \rVert \leq 1\) during the maneuver.


\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}
        \node (linearTPBVP) [process] {Solve linear TPBVP between pair of impulses};
        \node (firstcoast) [process, right = of linearTPBVP] {Backpropagate PV if \texttt{C...}};
        \node (lastcoast) [process, below = of firstcoast] {Propagate PV if \texttt{...C}};
        \node (diag) [decision, right = of firstcoast, text width=2cm] {Necessary conditions};
        \node (opt) [startstop, below = of diag] {Local optimum};
        \node (cont) [startstop, right = of diag] {More impulses};
    
        \draw [arrow] (linearTPBVP) to [out=45, in=90, looseness=3] (linearTPBVP);
        \draw [arrow] (linearTPBVP) -- (firstcoast);
        \draw [arrow] (firstcoast) -- (diag);
        \draw [arrow] (linearTPBVP) -- (lastcoast);
        \draw [arrow] (lastcoast) -- (diag);
        \draw [arrow] (diag) -- (opt);
        \draw [arrow] (diag) -- (cont);
    \end{tikzpicture}    
    \caption{Primer vector trajectory calculation algorithm, and conclusions that may be drawn from their analysis.}
    \label{fig:pv_calc}
\end{figure}


% \section{Lambert problem implementation}

% The formulations stated in the previous chapter make for one-dimensional nonlinear programs, which leads to high performance. However, they do not handle the singularity case of \(r_1 \parallel r_2\), which is of particular importance to orbital maneuvers as they often happen at periapsis and apoapsis. Sukhanov's formulation actually gives expressions for the initial radial and normal velocity when the input positions are collinear; the plane of the orbit should then be adequately chosen afterwards~\cite{sukhanov}. However, this was found to be very numerically sensitive and another algorithm was used in the rest of this work. An implicit orbit propagation algorithm, as described in Section~\ref{sec:orbit_propagation} is setup with boundary conditions

% \begin{align}
%     \mathbf{r}_{(j=1)}   &= \mathbf{r}_1 \\
%     \mathbf{r}_{(j=N+1)} &= \mathbf{r}_2
% \end{align}
% which account for the 6 boundary conditions needed. In order to help convergence in the collinear case (and neighboring cases), two inequality constraints may be added:
% \begin{align}
%     \mathbf{r}_j^T \mathbf{r}_j &\geq R_{\text{Earth}}^2 \\
%     \mathbf{r}_j \times \mathbf{v}_j &\geq 0
% \end{align}
% where the second constraint must be inverted if the desired orbit is retrograde. 

% The propagation variables are initialized with the initial position and velocity.


\section{Primer vector meta-algorithm}\label{sec:impulsive_statement}

Finally, with all of those components in place, an algorithm based on~\citeonline{interactive_primer_vector} was implemented, and is represented in Figure~\ref{fig:meta_alg}. First, a case with fixed time impulses, \texttt{ICI} is solved. Usually, this gives a local optimum with very high cost. Then, initial and final coasts are added, and the primer vector trajectory is analyzed. If the primer vector norm exceeds 1, an impulse is added and the algorithm is repeated. If the continuity of the primer vector's derivative is violated, more random guesses are executed until a continuous primer vector derivative trajectory is found. And finally, when all necessary conditions are met, the algorithm ends and returns a multiple-impulse local optimum.

\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}
        \node (2r) [startstop] {\texttt{ICI} Case};
        \node (2f) [process, right=of 2r] {\texttt{CICIC} Case};
        \node (pv) [decision, right=of 2f] {PV trajectory};
        \node (more_imp) [process, right=of pv] {Add one impulse \texttt{C} \(\rightarrow\) \texttt{CIC}};
        \node (end) [startstop, below=of pv] {Local Optimum};
    
        \draw [arrow] (2r) -- (2f);
        \draw [arrow] (2f) -- (pv);
        \draw [arrow] (pv) -- (more_imp);
        \draw [arrow] (pv) -- (end);
        \draw [arrow] (more_imp.north) |- (pv.north);
    \end{tikzpicture}    
    \caption{Meta-algorithm with optimization and primer vector analysis.}
    \label{fig:meta_alg}
\end{figure}
