\section{Optimal Control}

Optimal control is the area of control theory which tries to find the best control action to satisfy some requirements, such as altering a system's state in some way desired way. Here, "best" is defined as maximizing or minimizing some performance metric. In practice, and in particular in the scope of this work, this can be interpreted as attaining a target orbit in a certain amount of time, while minimizing fuel consumption.

The mathematical nature of an optimal control problem varies greatly depending on the nature of the system, the requirements, and the objective. Here, a selected subset of this vast theory shall be presented. Suppose a continuous time dynamical system operating on times \(t \in [0, t_f]\), where \(t_f \in \mathbb{R}\), given by

\begin{equation} \label{eq:generic_dyn}
    \dot X(t) = f(X(t), u(t))
\end{equation}
where \(X(t): \mathbb{R} \rightarrow \mathcal{X} \subset \mathbb{R}^n\) is the state vector trajectory describing the system state, \(u(t): \mathbb{R} \rightarrow \mathcal{U} \subset \mathbb{R}^m\) is the control vector trajectory and \(f: \mathbb{R}^n \times \mathbb{R}^m \rightarrow \mathbb{R}^n\) is the function describing its temporal dynamics. 

In addition, the control vector might be subject to some some inequality constraints, representing for instance saturation of actuators. Therefore, an admissible control set \(\mathcal{U}\) is defined by a vector of constraint functions \(g(u)\) as
\begin{equation}
    \mathcal{U} = \left\{u \in \mathbb{R}^m |\; g(u) \leq 0\right\}
\end{equation}
where the inequality is understood to hold component-wise.

At the initial time, the system is supposed to be in a given state \(X_i\) such that 
\begin{equation} \label{eq:generic_initial_constraint}
    X(0) = X_i
\end{equation}
and at the final time \(t_f\), it is desired that the system have a state \(X_f\) such that
\begin{equation} \label{eq:generic_final_constraint}
    X(t_f) = X_f.
\end{equation}

To complete the optimal control problem, a performance metric needs to be introduced. In general, any functional of the form \(J[X(t), u(t)]\) may be taken as this performance metric; however, a common form with desireable properties, which shall be adopted in this work, is given by
\begin{equation} \label{eq:generic_cost}
    J[X(t), u(t)] = h(X(t_f)) + \int_0^{t_f} L(X(t), u(t)) dt
\end{equation}
where the functions \(h(X)\) and \(L(X, u)\) are respectively called the \textit{terminal cost} and the \textit{temporal cost} functions.\

The optimal control problem is then that of finding a control trajectory \(u(t)\) that minimizes (or maximizes) the performance metric. Here the problem shall be presented as a minimization problem; but the formulation is perfectly analogous for a maximization problem. That said, the complete optimal control problem may be stated as finding the function \(u(t)\) such that

\begin{equation} \label{eq:argmin_cost}
    u(t) = \arg \min_{u(t), X(t)} J[X(t), u(t)]
\end{equation}
subject to
\begin{align}
    \dot X(t) &= f(X(t), u(t)) \\
    X(0) &= X_i \\
    X(t_f) &= X_f
\end{align}

In general, this is a very hard problem. The optimization variable \(u(t)\) is not merely a vector of parameters but a whole trajectory of them; thus, the search space is enormous. There are techniques to turn this problem into a simple parameter optimization problem, which are known as \textit{direct methods}, which shall be discussed later. There are however tools for extracting necessary conditions for the solution of this problem at all points in time. These are known as \textit{indirect methods}.

One of this tools is the Hamiltonian, a quantity that describes the ensemble of objectives and constraints. It shall be defined for a minimization problem, and maximization problems can be adapted by changing the sign of the performance metric. Given a system of the form in equation~\eqref{eq:generic_dyn}, constraints in the forms of~\eqref{eq:generic_initial_constraint} and~\eqref{eq:generic_final_constraint}, and a cost function in the form~\eqref{eq:generic_cost}, the Hamiltonian \(H\) is defined as
\begin{equation}
    H(X(t), u(t), \lambda(t)) = L(X, u) + \lambda{(t)}^T f(X, u)
\end{equation}

for all times \(t\), state and control vectors \(X  \) and \(u\) along a trajectory.\ \( \lambda(t) \) is the costate trajectory, a new set of variables introduced as the continuous-time equivalent of Lagrangian multipliers. These new variables are subject to the differential equation
\begin{equation}
    \dot \lambda = - \left( \frac{\partial H}{\partial X} \right)^T = -\left( \frac{\partial f}{\partial X} \right)^T \lambda - \left( \frac{\partial L}{\partial X} \right)^T
\end{equation}

To complete the Hamiltonian approach, Pontryagin's Minimum Principle is introduced. It states that a necessary condition for attaining the minimum in equation~\eqref{eq:argmin_cost} is that, at all times \(t\), and along the optimal trajectory,
\begin{equation} \label{eq:Pontryagin}
    u(t) = \arg \min_{u \in \mathcal{U}} H[X(t), u, \lambda(t)].
\end{equation}

With the control trajectory obtained as a function of \(X(t)\) and \(\lambda(t)\) from equation~\eqref{eq:Pontryagin}, there are 2n variables, the state and costate trajectories, and 2n boundary conditions, the initial and final states. Thus, the problem is well-posed and configures a Two Point Boundary Value Problem (TPBVP).

\section{Orbital Mechanics}

Orbital mechanics concerns itself with the motion of bodies in space subject to gravitational and disturbance forces. A variety of models exist, differing in precision and availability of analytical tools. The simpler the model, the more analytical tools are available, and the smaller the precision. The simplest model of all, and the basis for all others, is the two body problem, where a central massive body is supposed to be stationary while a moving satellite is subject to its gravitational attraction, also known as Keplerian motion. 

\subsection{Two Body Motion}

Let \(r\) be the 3-dimensional position of a satellite, and \(\mu \) the gravitational parameter of the central body. The dynamics of the satellite's position are given by
\begin{equation} \label{eq:kepler_dyn}
    \ddot{r} = -\frac{\mu}{\lVert r \rVert^3} r,
\end{equation}
thus configuring a 6-dimensional state vector \(X = \begin{bmatrix}
    r^T & v^T
\end{bmatrix}^T\), where \(v\) is the satellite's velocity. The system contains a singularity at the states with \(\lVert r \rVert = 0\), which configures a non-convex domain. In practice, this point is rarely encountered as it lies inside of the central body, thus far from the regions of interest. It is proven that no analytical solution exists for this differential equation; however, much is known about its solutions.

In this model, the possible trajectories are known to be conics, and therefore restricted to a plane. For bound satellites, that is, those in orbit around the central body, this trajectory is an ellipse where the central body lies on one of its foci. Mathematically, a ``bound'' satellite is one whose specific energy (mechanical energy over mass of the satellite), given by
\begin{equation}
    \epsilon = -\frac{\mu}{\lVert r \rVert} + \frac{v^2}{2},
\end{equation}
is negative. The trajectory is closed, and the movement is periodic with period
\begin{equation}
    T = 2\pi \sqrt{\frac{a^3}{\mu}}
\end{equation}
where \(a\) is the semi-major axis of the ellipse.

In this case, an alternative state vector may be introduced in the form of the Keplerian elements. These are:
\begin{itemize}
    \item \(a\): semi-major axis of the ellipse;
    \item \(e\): excentricity of the ellipse;
    \item \(i\): inclination of the orbit's plane with respect to the Equatorial plane;
    \item \(\Omega \): right ascension of the ascending node, that is, angle between FIND REFERENCE DIRECTION and the direction where the satellite crosses the Equatorial plane from South to North;
    \item \(\omega \): argument of perigee, or angle, in the plane of the orbit, between the ascending node and the perigee (point of smallest distance to the central body);
    \item \(\theta \): true anomaly, or angle between the perigee and the current position of the satellite.
\end{itemize}

These elements are related to the Cartesian state vector through ADD PERIFOCAL EQUATIONS.

In this formulation, all elements but the true anomaly are constant in time. The true anomaly can be related to time implictly through two other quantities, the mean anomaly \(M\) and the excentric anomaly \(E\):

\begin{align} 
        M &= 2\pi \frac{t - t_p}{T} \\
        E - e \sin{E} &= M \label{eq:kepler_equation}\\
        \tan{\frac{\theta}{2}} &= \sqrt{\frac{1+e}{1-e}} \tan{\frac{E}{2}} \label{eq:true_exc_anom}
\end{align}
where \(t_p\) is the time of the last perigee passage. By computing the mean anomalies in an initial and a final time, and solving the notorious Kepler's equation~\eqref{eq:kepler_equation}, and finally finding a suitable true anomaly with~\eqref{eq:true_exc_anom}, a semi-analytical temporal solution can be found. The process of finding the position of a satellite in the future is called \textit{orbit propagation}.


\subsection{Lambert's Problem}

An important problem in orbital mechanics is that of the determination of the initial and final velocities of a satellite that passes through two points in space \(r_1\) and \(r_2\) with a time interval \(\Delta t\) in between. This problem first arose in the field of orbit determination but also finds application in the context of orbital maneuvers. Namely, Lambert's Problem seeks to find a feasible solution to a TPBVP, which is of interest to the optimal control TPBVP.

In general, this problem can have multiple solutions, corresponding to prograde and retrograde trajectories, with less than one or multiple revolutions. The resulting orbit can, in general, be elliptic, parabolic or hyperbolic. 

Many formulations exist, including CURTIS, SUKHANOV, and numerical integration. They all suffer from a physical indetermination in the case of collinear \(r_1\) and \(r_2\): the plane of the orbit is indeterminate. In this case, one can find many feasible solutions but determining exact velocities requires extra information about the plane of the orbit.\

% try battin vaughan? 

\section{Orbital Maneuvers}

When a satellite is able to maneuver, the Keplerian dynamics of equation~\eqref{eq:kepler_dyn} need to be augmented with the thrust control vector \(F\), which applies a propulsion force on the satellite. Supposing that \(m\) is the total current mass of the spacecraft, the dynamics are given by
\begin{equation}
    \ddot r = -\frac{\mu}{\lvert r \rVert^3}r + \frac{F}{m}.
\end{equation}

The generation of thrust \(F\) is tied to the consumption of propellant, \(-\dot m\), according to some propulsion model to be discussed in the next section.

The application of optimal control to the field of orbital maneuvering is mainly concerned with the preservation of propellant. Suppose a satellite has an orbital state \(X_i\) and is required to maneuver to a state \(X_f\) in a time \(t_f\), and it is desired to minimize the amount of propellant used. A convenient way of expressing this is that it is desired to maximize the final mass of the spacecraft:
\begin{align}
    \max_{F(t)}&\quad m(t_f) \label{eq:max_final_mass} \\
    X(0) &= X_i \\
    X(t_f) &= X_f
\end{align}

\subsection{Propulsion models}

\subsubsection{Impulsive thrust}

The most traditional propulsion model supposes that the propulsive forces are much greater and operate much faster than the gravitational force, introducing discontinuities in velocity. This is called \textit{impulsive thrust}. The propulsion model relies on Tsiolkovsky's equation, 
\begin{equation}
    \Delta v = v_e \ln{\left(\frac{m_i}{m_f}\right)},
\end{equation}
where \(\Delta v\) is the magnitude of an instantaneous change in velocity, \(v_e\) is the engine's exhaust velocity (which is treated as a known parameter), \(m_i\) is the initial spacecraft amss and \(m_f\), the final mass. Supposing a burn happens at time \(t_b\), the propulsion model can then be expressed through a Dirac delta as
\begin{equation}
    \left.\frac{F}{m}\right\vert_{t = t_b} = \delta(t - t_b) V_e \ln{\left(\frac{m(t_b^-)}{m(t_b^+)} \right)} = \delta(t - t_b) \Delta v,
\end{equation}
which yields a velocity discontinuity
\begin{equation}
    \lVert v(t_b^+) - v(t_b^-) \rVert = V_e \ln{\left(\frac{m(t_b^-)}{m(t_b^+)}\right)} = \Delta v.
\end{equation}

Now, considering a generic maneuver with \(n\) burns, there are \(n+1\) coasting segments related by the change in velocity \(\Delta \vec v_j\) associated with the j-th burn. Considering burn times \(t_j\), with \(t_f \geq t_{j+1} \geq t_j \geq 0\), and the initial and final times \(0\) and \(t_f\), the system is subject to boundary conditions
\begin{align}
    X(0) &= X_i \\
    r(t_j^+) &= r(t_j^-),& \forall j=1,\dots,n \\
    v(t_j^+) &= v(t_j^-) + \Delta \vec v_j,& \forall j=1,\dots,n \\
    X(t_f) &= X_f
\end{align}
and to dynamical equation~\eqref{eq:kepler_dyn} in the intermediate times. Each impulse is described by its time \(t_j\) and its velocity change vector \(\Delta v_j\). DOF discussion


Tsiolkovsky's equation can also be applied between the initial time and the final time, thus relating mass at time \(t_f\) with the total velocity change, which is the sum of all \(n\) burns executed during the transfer:
\begin{equation}
    m(t_f) = m(0) \exp{\left(-\frac{\sum_{i=1}^{n}\Delta v_i}{v_e}\right)}
\end{equation}

Since \(v_e\) and \(m(0)\) are not subject to optimization, the objective~\eqref{eq:max_final_mass} is equivalent to minimizing the sum of magnitudes of impulses used during the transfer:
\begin{equation}
    \min \sum_{i=1}^{n} \Delta v_i.
\end{equation}

Thus, in the impulsive case, the problem is \textit{independent of spacecraft mass}. However, the introduction of a discrete parameter, the number of burns \(n\), is worth discussing. The optimization of non linear problems with mixed continuous and discrete variables is called Mixed Integer Non-Linear Programming (MINLP), and is much more complicated than regular non-linear programming. Although the implementation of such a solver might be of interest, some simple reasoning and the theory of primer vectors (exposed later) can help determine the number of impulses needed.

\subsubsection{Finite constant specific impulse thrust}


impulsive thrust as a limiting case

\subsubsection{Finite variable specific impulse thrust}

\subsection{Primer vector theory}

